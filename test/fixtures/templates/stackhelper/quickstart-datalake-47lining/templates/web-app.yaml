---
AWSTemplateFormatVersion: '2010-09-09'
Description: AWS Cloudformation template to create an EC2 instance, installs Data
  Lake walk-through webapp and creates ELB. **WARNING** This template creates an Amazon
  EC2 instance. You will be billed for the AWS resources used if you create a stack
  from this template. (qs-1nlkhq1pd)
Parameters:
  ApplicationPassword:
    Description: Web server password
    NoEcho: 'true'
    Type: String
  ApplicationUsername:
    Description: Web server username
    Type: String
  AthenaQueryResultsBucketName:
    Description: Athena query results bucket name for the Quick Start Athena query
      results. Athena query results bucket name can include numbers, lowercase letters,
      uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
    Type: String
  CleanOrdersStreamARN:
    Description: Clean orders stream ARN
    Type: String
  CleanupResourcesRoleARN:
    Description: CleanupResourcesRole ARN
    Type: String
  DatasetS3BucketName:
    Description: Dataset bucket name for the Quick Start dataset. Dataset bucket name
      can include numbers, lowercase letters, uppercase letters, and hyphens (-).
      It cannot start or end with a hyphen (-).
    Type: String
  DatasetS3KeyPrefix:
    Description: S3 key prefix for the Quick Start dataset. Dataset key prefix can
      include numbers, lowercase letters, uppercase letters, hyphens (-), and forward
      slash (/).
    Type: String
  ElasticsearchEndpoint:
    Description: Elasticsearch endpoint
    Type: String
  InstanceProfileName:
    Description: InstanceProfile Name
    Type: String
  WizardInstanceType:
    AllowedValues:
    - t2.nano
    - t2.micro
    - t2.small
    - t2.medium
    - t2.large
    - m3.large
    - m3.xlarge
    - m3.2xlarge
    ConstraintDescription: must be a valid EC2 instance type.
    Default: t2.micro
    Description: Web server EC2 instance type
    Type: String
  KeyName:
    ConstraintDescription: Can contain only ASCII characters.
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Type: AWS::EC2::KeyPair::KeyName
  KibanaURL:
    Description: Kibana URL
    Type: String
  KinesisAnalyticsRoleARN:
    Description: Kinesis analytics role ARN
    Type: String
  CuratedBucketARN:
    Description: Curated bucket ARN
    Type: String
  CuratedBucketName:
    Description: Bucket name for curated datasets
    Type: String
  NumWebServerInstances:
    Description: Number or web server instances in Auto scaling group
    Type: Number
  OrdersStreamARN:
    Description: Orders stream ARN
    Type: String
  OrdersStreamName:
    Description: Orders stream name
    Type: String
  PrivateSubnet1ID:
    Description: Web server subnet 1
    Type: AWS::EC2::Subnet::Id
  PrivateSubnet2ID:
    Description: Web server subnet 2
    Type: AWS::EC2::Subnet::Id
  PublicSubnet1ID:
    Description: Elastic load balancer subnet 1
    Type: AWS::EC2::Subnet::Id
  PublicSubnet2ID:
    Description: Elastic load balancer subnet 2
    Type: AWS::EC2::Subnet::Id
  PublishedBucketName:
    Description: Bucket name for published results
    Type: String
  QSS3BucketName:
    Description: S3 bucket name for the Quick Start assets. Quick Start bucket name
      can include numbers, lowercase letters, uppercase letters, and hyphens (-).
      It cannot start or end with a hyphen (-).
    Type: String
  QSS3KeyPrefix:
    Description: S3 key prefix for the Quick Start assets. Quick Start key prefix
      can include numbers, lowercase letters, uppercase letters, hyphens (-), and
      forward slash (/). It cannot start or end with forward slash (/) because they
      are automatically appended.
    Type: String
  RedshiftConnectionURL:
    Description: JDBC redshift connection URL
    Type: String
  RedshiftPassword:
    Description: Redshift password
    NoEcho: 'true'
    Type: String
  RedshiftRoleARN:
    Description: Redshift role ARN
    Type: String
  RedshiftUsername:
    Description: Redshift username
    Type: String
  RevenueByStateStreamARN:
    Description: Revenue by state stream ARN
    Type: String
  SnsLearnMoreTopicArn:
    Description: SNS Topic ARN for Learn More topic
    Type: String
  SubmissionsBucketARN:
    Description: Submissions bucket ARN
    Type: String
  SubmissionsBucketName:
    Description: Bucket name for submissions
    Type: String
  TopSKUStreamARN:
    Description: Top SKU stream ARN
    Type: String
  VPCCIDR:
    Description: CIDR block for the VPC
    Type: String
  VpcId:
    Description: Web server VPC
    Type: AWS::EC2::VPC::Id
  CuratedDatasetsDatabaseName:
    Description: Curated Datasets database name
    Type: String
  CuratedDatasetsCrawlerName:
    Description: Curated Datasets crawler name
    Type: String
  CuratedDatasetsJobName:
    Description: Curated Datasets job name
    Type: String
  SageMakerNotebookInstanceName:
    Description: SageMaker notebook instance name
    Type: String
  SageMakerNotebookName:
    Description: SageMaker notebook name
    Type: String
  SageMakerModelName:
    Description: SageMaker model name
    Type: String
  SageMakerModelEndpointName:
    Description: SageMaker model endpoint name
    Type: String
Mappings:
  AWSAMIRegionMap:
    AMI:
      AMZNLINUXHVM: amzn-ami-hvm-2018.03.0.20181129-x86_64-gp2
    us-east-1:
      AMI: ami-c58c1dd3
      AMZNLINUXHVM: ami-0080e4c5bc078760e
    us-west-2:
      AMI: ami-4836a428
      AMZNLINUXHVM: ami-01e24be29428c15b2
Resources:
  CleanupResources:
    Properties:
      AthenaQueryResultsBucket: !Ref AthenaQueryResultsBucketName
      CuratedDatasets: !Ref CuratedBucketName
      PublishedData: !Ref PublishedBucketName
      ServiceToken: !GetAtt CleanupResourcesFunction.Arn
      SubmissionsBucket: !Ref SubmissionsBucketName
    Type: AWS::CloudFormation::CustomResource
  CleanupResourcesFunction:
    Properties:
      Code:
        ZipFile:
          !Join
          - '

            '
          - - import json
            - import cfnresponse
            - import boto3
            - from time import sleep
            - from botocore.exceptions import ClientError
            - ''
            - s3 = boto3.resource('s3')
            - ka_client = boto3.client('kinesisanalytics')
            - ''
            - 'def handler(event, context):'
            - '    submissions_bucket = s3.Bucket(event[''ResourceProperties''][''SubmissionsBucket''])'
            - '    curated_datasets = s3.Bucket(event[''ResourceProperties''][''CuratedDatasets''])'
            - '    published_data = s3.Bucket(event[''ResourceProperties''][''PublishedData''])'
            - '    athena_query_results_bucket = s3.Bucket(event[''ResourceProperties''][''AthenaQueryResultsBucket''])'
            - '    if event[''RequestType''] == ''Delete'':'
            - '        try:'
            - '           submissions_bucket.objects.all().delete()'
            - '           curated_datasets.objects.all().delete()'
            - '           published_data.objects.all().delete()'
            - '           athena_query_results_bucket.objects.all().delete()'
            - '           response = ka_client.list_applications()'
            - '           for app in filter(lambda ap: ap[''ApplicationName''] in
              {''clean-orders-app'', ''aggregate-orders-app''}, response[''ApplicationSummaries'']):'
            - '              described_app = ka_client.describe_application(ApplicationName=app[''ApplicationName''])'
            - '              delete_response = ka_client.delete_application(ApplicationName=app[''ApplicationName''],'
            - '                  CreateTimestamp=described_app[''ApplicationDetail''][''CreateTimestamp''])'
            - '           return cfnresponse.send(event, context, cfnresponse.SUCCESS,
              {})'
            - '        except ClientError as e:'
            - '            print(e)'
            - '            return cfnresponse.send(event, context, cfnresponse.FAILED,
              {})'
            - '    else:'
            - '        return cfnresponse.send(event, context, cfnresponse.SUCCESS,
              {})'
      Handler: index.handler
      Role: !Ref CleanupResourcesRoleARN
      Runtime: python3.6
      Timeout: 30
    Type: AWS::Lambda::Function
  ELBSecurityGroup:
    Properties:
      GroupDescription: Enable Elastic Load Balancer access via port 80
      SecurityGroupIngress:
      - CidrIp: 0.0.0.0/0
        FromPort: '80'
        IpProtocol: tcp
        ToPort: '80'
      VpcId: !Ref VpcId
    Type: AWS::EC2::SecurityGroup
  ElasticLoadBalancer:
    Properties:
      ConnectionSettings:
        IdleTimeout: '300'
      Listeners:
      - InstancePort: '2000'
        LoadBalancerPort: '80'
        Protocol: HTTP
      SecurityGroups:
      - !Ref ELBSecurityGroup
      Subnets:
      - !Ref PublicSubnet1ID
      - !Ref PublicSubnet2ID
    Type: AWS::ElasticLoadBalancing::LoadBalancer
  InstanceSecurityGroup:
    Properties:
      GroupDescription: Enable SSH access from Bastion via port 22, and from ELB via
        port range 1024-65535
      SecurityGroupIngress:
      - CidrIp: !Ref VPCCIDR
        FromPort: '22'
        IpProtocol: tcp
        ToPort: '22'
      - FromPort: '1024'
        IpProtocol: tcp
        SourceSecurityGroupId: !Ref ELBSecurityGroup
        ToPort: '65535'
      VpcId: !Ref VpcId
    Type: AWS::EC2::SecurityGroup
  WebServerAutoScalingGroup:
    CreationPolicy:
      ResourceSignal:
        Count: !Ref NumWebServerInstances
        Timeout: PT15M
    Properties:
      Cooldown: '300'
      DesiredCapacity: !Ref NumWebServerInstances
      LaunchConfigurationName: !Ref WebServerLaunchConfiguration
      LoadBalancerNames:
      - !Ref ElasticLoadBalancer
      MaxSize: !Ref NumWebServerInstances
      MinSize: !Ref NumWebServerInstances
      Tags:
      - Key: Name
        PropagateAtLaunch: 'true'
        Value: DataLakeWalkthroughWebapp
      VPCZoneIdentifier:
      - !Ref PrivateSubnet1ID
      - !Ref PrivateSubnet2ID
    Type: AWS::AutoScaling::AutoScalingGroup
  WebServerLaunchConfiguration:
    Metadata:
      AWS::CloudFormation::Init:
        config:
          commands:
            1_run_bootstrap:
              command: sh -e /etc/bootstrap.sh
            9_run_webserver:
              command: runuser -l ec2-user -c "python3.4 /home/ec2-user/assets/web/app.py
                --config /etc/production.ini > server.log 2>&1 &"
          files:
            /etc/bootstrap.sh:
              content: !Sub |
                # Install python requirements
                pip-3.4 install flask==0.12.1
                pip-3.4 install awscli==1.11.84
                pip-3.4 install psycopg2==2.7.1
                pip-3.4 install jinja2==2.9.6
                pip-3.4 install boto3==1.7.28
                alias aws=/usr/local/bin/aws
                aws s3 cp s3://${SubmissionsBucketName}/metadata/customers_metadata.json /home/ec2-user/
                cd /home/ec2-user
                aws s3 cp s3://${QSS3BucketName}/${QSS3KeyPrefix}assets/assets.zip .
                unzip assets.zip
                rm assets.zip
                cd /home/ec2-user/assets
                python3.4 setup.py develop
                chown -R ec2-user:ec2-user /home/ec2-user
                python3.4 kibana/import_analysis_dashboard.py --elasticsearch-endpoint ${ElasticsearchEndpoint}
              group: ec2-user
              mode: '000770'
              owner: ec2-user
            /etc/production.ini:
              content:
                !Join
                - '

                  '
                - - '[webapp]'
                  - port=2000
                  - !Sub webapp_username=${ApplicationUsername}
                  - !Sub webapp_password=${ApplicationPassword}
                  - '[aws]'
                  - !Sub region_name=${AWS::Region}
                  - !Sub account_number=${AWS::AccountId}
                  - '[redshift]'
                  - !Sub redshift_username=${RedshiftUsername}
                  - !Sub redshift_password=${RedshiftPassword}
                  - !Sub redshift_jdbc_url=${RedshiftConnectionURL}
                  - !Sub redshift_role_arn=${RedshiftRoleARN}
                  - redshift_external_schema_name=data_lake
                  - '[buckets]'
                  - !Sub submissions_bucket_name=${SubmissionsBucketName}
                  - !Sub submissions_bucket_arn=${SubmissionsBucketARN}
                  - !Sub curated_bucket_name=${CuratedBucketName}
                  - !Sub curated_bucket_arn=${CuratedBucketARN}
                  - !Sub published_bucket_name=${PublishedBucketName}
                  - demographics_submission_path=demographics/2017/06/02/demographics20170520.zip
                  - demographics_curated_path=demographics_20170520_json/dataset=demographics/v=2017-05-20/p=json/dt=2017-06-01/demographics_data.json
                  - demographics_curated_dir=demographics_20170520_json/dataset=demographics/v=2017-05-20/p=json/
                  - demographics_partition=2017-06-01
                  - customers_submission_path=customers/2017/06/01/customers.json
                  - customers_curated_path=customers_20170601_json/dataset=customers/v=2017-06-01/p=json/dt=2017-06-01/customers.json
                  - customers_curated_dir=customers_20170601_json/dataset=customers/v=2017-06-01/p=json/
                  - orders_submission_path=orders/2017/06/01/orders.json
                  - orders_curated_path=orders_20170601_json/dataset=orders/v=2017-06-01/p=json/dt=2017-06-01/orders.json
                  - orders_curated_dir=orders_20170601_json/dataset=orders/v=2017-06-01/p=json/
                  - products_submission_path=products/2017/06/01/products.json
                  - products_curated_dir=products_20170601_json/dataset=products/v=2017-06-01/p=json/
                  - '[streams]'
                  - !Sub orders_stream_name=${OrdersStreamName}
                  - !Sub orders_stream_arn=${OrdersStreamARN}
                  - !Sub clean_orders_stream_arn=${CleanOrdersStreamARN}
                  - !Sub revenue_by_state_stream_arn=${RevenueByStateStreamARN}
                  - !Sub top_sku_stream_arn=${TopSKUStreamARN}
                  - !Sub kinesis_analytics_role_arn=${KinesisAnalyticsRoleARN}
                  - generator_sleep_interval=0.5
                  - generator_chunk_size=5
                  - generator_events_count=30000
                  - generator_customers_path=/home/ec2-user/customers_metadata.json
                  - '[kibana]'
                  - !Sub kibana_url=${KibanaURL}
                  - '[athena]'
                  - !Sub athena_query_results_bucket_name=${AthenaQueryResultsBucketName}
                  - '[sns]'
                  - !Sub sns_learn_more_topic_arn=${SnsLearnMoreTopicArn}
                  - '[glue]'
                  - !Sub curated_datasets_database_name=${CuratedDatasetsDatabaseName}
                  - !Sub curated_datasets_crawler_name=${CuratedDatasetsCrawlerName}
                  - !Sub curated_datasets_job_name=${CuratedDatasetsJobName}
                  - '[sagemaker]'
                  - !Sub sm_instance_name=${SageMakerNotebookInstanceName}
                  - !Sub sm_notebook_name=${SageMakerNotebookName}
                  - !Sub sm_model_name=${SageMakerModelName}
                  - !Sub sm_model_endpoint_name=${SageMakerModelEndpointName}
                  - products_parquet_table_name=products_20170601_parquet
                  - demographics_parquet_table_name=demographics_20170520_parquet
              group: ec2-user
              mode: '000444'
              owner: ec2-user
          packages:
            yum:
              gcc: []
              postgresql93-devel: []
              python34: []
              python34-devel: []
              python34-pip: []
      Comment: Install Flask application
    Properties:
      IamInstanceProfile: !Ref InstanceProfileName
      ImageId:
        !FindInMap
        - AWSAMIRegionMap
        - !Ref AWS::Region
        - AMI
      InstanceType: !Ref WizardInstanceType
      KeyName: !Ref KeyName
      SecurityGroups:
      - !Ref InstanceSecurityGroup
      UserData:
        !Base64
          Fn::Join:
          - '

            '
          - - '#!/bin/bash'
            - yum update -y
            - yum install -y aws-cfn-bootstrap
            - '# Install the files and packages from the metadata'
            - !Sub /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource WebServerLaunchConfiguration --region ${AWS::Region}
            - '# Signal the status from cfn-init'
            - !Sub /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource WebServerAutoScalingGroup --region ${AWS::Region}
    Type: AWS::AutoScaling::LaunchConfiguration
Outputs:
  URL:
    Value: !GetAtt ElasticLoadBalancer.CanonicalHostedZoneName
    Description: ELB URL
...
